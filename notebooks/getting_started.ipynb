{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/05 09:26:35 WARN Utils: Your hostname, codespaces-43f4cb resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
      "22/12/05 09:26:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/05 09:26:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/codespace/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# initialize sparksession\n",
    "spark = SparkSession.builder.appName('app').getOrCreate()\n",
    "\n",
    "# initialize list of lists of random data\n",
    "data = [['Rand1', 'C34,C18,C19', '2021-01-01'], \n",
    "        ['Rand1', 'C34,C18,C19', '2020-12-29'],\n",
    "        ['Rand3', 'C50', '2021-07-10'], \n",
    "        ['Rand3', 'C50,C21,C50', '2021-04-01'], \n",
    "        ['Rand3', 'J12, C20', '2021-06-01'],\n",
    "        ['Rand3', 'J12, C20', '2021-06-02'] ]\n",
    "#\n",
    "#  Create the pandas DataFrame\n",
    "df = pd.DataFrame(data, columns = ['dummy_name', 'dummy_condition','dummy_admis'])\n",
    "\n",
    "#convert to sparkdf\n",
    "spark_df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----------+\n",
      "|dummy_name|dummy_condition|dummy_admis|\n",
      "+----------+---------------+-----------+\n",
      "|     Rand1|    C34,C18,C19| 2021-01-01|\n",
      "|     Rand1|    C34,C18,C19| 2020-12-29|\n",
      "|     Rand3|            C50| 2021-07-10|\n",
      "|     Rand3|    C50,C21,C50| 2021-04-01|\n",
      "|     Rand3|       J12, C20| 2021-06-01|\n",
      "|     Rand3|       J12, C20| 2021-06-02|\n",
      "+----------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
